{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26d4d114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hospital Clínic', 'Hospital Josep Trueta', 'Hospital Sant Pau', 'Hospital Vall Hebrón', 'README', 'all_data_inc_trueta.xlsx']\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "\n",
    "path = \"/media/cansu/DiskSpace/Cansu/HE_Prediction/RAINS_vicorob\"\n",
    "all_files = os.listdir(path)\n",
    "all_files.sort()\n",
    "print(all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64a5c762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hospital name</th>\n",
       "      <th>id</th>\n",
       "      <th>Basal volume, ml</th>\n",
       "      <th>FU volume, ml</th>\n",
       "      <th>Absolute vol diff, ml</th>\n",
       "      <th>Relative vol diff (FU_vol/Basal_vol)</th>\n",
       "      <th>HE vicorob</th>\n",
       "      <th>HE real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hospital Clínic</td>\n",
       "      <td>2098</td>\n",
       "      <td>5.02</td>\n",
       "      <td>4.87</td>\n",
       "      <td>-0.150</td>\n",
       "      <td>0.970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hospital Clínic</td>\n",
       "      <td>233632</td>\n",
       "      <td>36.07</td>\n",
       "      <td>39.24</td>\n",
       "      <td>3.171</td>\n",
       "      <td>1.088</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hospital Clínic</td>\n",
       "      <td>261065</td>\n",
       "      <td>9.50</td>\n",
       "      <td>11.41</td>\n",
       "      <td>1.915</td>\n",
       "      <td>1.202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hospital Clínic</td>\n",
       "      <td>34333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hospital Clínic</td>\n",
       "      <td>397280</td>\n",
       "      <td>9.37</td>\n",
       "      <td>8.33</td>\n",
       "      <td>-1.038</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Hospital name      id  Basal volume, ml  FU volume, ml  \\\n",
       "0  Hospital Clínic    2098              5.02           4.87   \n",
       "1  Hospital Clínic  233632             36.07          39.24   \n",
       "2  Hospital Clínic  261065              9.50          11.41   \n",
       "3  Hospital Clínic   34333               NaN            NaN   \n",
       "4  Hospital Clínic  397280              9.37           8.33   \n",
       "\n",
       "   Absolute vol diff, ml  Relative vol diff (FU_vol/Basal_vol)  HE vicorob  \\\n",
       "0                 -0.150                                 0.970         0.0   \n",
       "1                  3.171                                 1.088         0.0   \n",
       "2                  1.915                                 1.202         0.0   \n",
       "3                    NaN                                   NaN         NaN   \n",
       "4                 -1.038                                 0.889         0.0   \n",
       "\n",
       "   HE real  \n",
       "0      NaN  \n",
       "1      NaN  \n",
       "2      NaN  \n",
       "3      NaN  \n",
       "4      NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "excel_file = \"/media/cansu/DiskSpace/Cansu/HE_Prediction/RAINS_vicorob/all_data_inc_trueta.xlsx\"\n",
    "df = pd.read_excel(excel_file)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5163cb6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated dataframe saved to /media/cansu/DiskSpace/Cansu/HE_Prediction/RAINS_vicorob/all_data_inc_trueta.xlsx\n"
     ]
    }
   ],
   "source": [
    "# for all the cases of hospital sant pau, make their ids 3 digits by adding leading zeros\n",
    "df.loc[df['Hospital name'] == 'Hospital Sant Pau', 'id'] = df.loc[df['Hospital name'] == 'Hospital Sant Pau', 'id'].apply(lambda x: str(x).zfill(3))\n",
    "df.loc[df['Hospital name'] == 'Hospital Vall Hebrón', 'id'] = df.loc[df['Hospital name'] == 'Hospital Vall Hebrón', 'id'].apply(lambda x: str(x).zfill(3))\n",
    "df.head()\n",
    "\n",
    "# save updated dataframe to excel file\n",
    "output_excel = \"/media/cansu/DiskSpace/Cansu/HE_Prediction/RAINS_vicorob/all_data_inc_trueta.xlsx\"\n",
    "df.to_excel(output_excel, index=False)\n",
    "print(f\"Updated dataframe saved to {output_excel}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c44cb2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hospital Clínic',\n",
       " 'Hospital Josep Trueta',\n",
       " 'Hospital Sant Pau',\n",
       " 'Hospital Vall Hebrón',\n",
       " 'README',\n",
       " 'all_data_inc_trueta.xlsx']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70015fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing entries (hospital, id, has_basal, has_fu): 24\n",
      "[('Hospital Clínic', '34333', True, False), ('Hospital Clínic', '4084062', True, False), ('Hospital Clínic', '4731571', True, False), ('Hospital Clínic', '5229590', True, False), ('Hospital Clínic', '5281637', True, False), ('Hospital Clínic', '5295375', True, False), ('Hospital Clínic', '600801', True, False), ('Hospital Clínic', '70293754', True, False), ('Hospital Clínic', '70588150', True, False), ('Hospital Sant Pau', '016', True, False), ('Hospital Sant Pau', '033', True, False), ('Hospital Vall Hebrón', '016', True, False), ('Hospital Vall Hebrón', '017', True, False), ('Hospital Vall Hebrón', '023', True, False), ('Hospital Vall Hebrón', '053', True, False), ('Hospital Vall Hebrón', '054', True, False), ('Hospital Vall Hebrón', '056', False, True), ('Hospital Vall Hebrón', '097', True, False), ('Hospital Vall Hebrón', '121', True, False), ('Hospital Vall Hebrón', '126', True, False), ('Hospital Vall Hebrón', '139', True, False), ('Hospital Vall Hebrón', '165', True, False), ('Hospital Vall Hebrón', '171', True, False), ('Hospital Vall Hebrón', '178', True, False)]\n",
      "Saved CSV with paths to all_data_with_paths.csv\n"
     ]
    }
   ],
   "source": [
    "# create a csv file to read the data easily.\n",
    "# For each patient find Basal and FU paths and save to df columns\n",
    "\n",
    "# add 2 new columns for the paths\n",
    "df['basal_img_path'] = ''\n",
    "df['basal_mask_path'] = ''\n",
    "df['fu_img_path'] = ''\n",
    "df['fu_mask_path'] = ''\n",
    "\n",
    "base_path = \"/media/cansu/DiskSpace/Cansu/HE_Prediction/RAINS_vicorob\"\n",
    "\n",
    "def collect_files(hospital_dir):\n",
    "    files = []\n",
    "    for root, _, filenames in os.walk(hospital_dir):\n",
    "        for fname in filenames:\n",
    "            if fname.lower().endswith(('.nii', '.nii.gz', '.mha', '.nrrd')):\n",
    "                files.append(os.path.join(root, fname))\n",
    "    return files\n",
    "\n",
    "missing = []\n",
    "for hospital in df['Hospital name'].unique():\n",
    "    hosp_dir = os.path.join(base_path, hospital)\n",
    "    hospital_df = df[df['Hospital name'] == hospital]\n",
    "\n",
    "    for index, row in hospital_df.iterrows():\n",
    "        pid = str(row['id'])\n",
    "        basal_path = os.path.join(hosp_dir, pid, 'Basal')\n",
    "        fu_path = os.path.join(hosp_dir, pid, 'FU1')\n",
    "\n",
    "        basal_image = os.path.join(basal_path, f\"CT_SS.nii.gz\")\n",
    "        basal_mask = os.path.join(basal_path, f\"hematoma_mask_vicorob_reviewed_reoriented.nii.gz\")\n",
    "        fu_image = os.path.join(fu_path, f\"CT_SS.nii.gz\")\n",
    "        fu_mask = os.path.join(fu_path, f\"hematoma_mask_vicorob_reviewed_reoriented.nii.gz\")\n",
    "\n",
    "        # record paths (empty string if not found)\n",
    "        df.at[index, 'basal_img_path'] = basal_image if os.path.exists(basal_image) else ''\n",
    "        df.at[index, 'basal_mask_path'] = basal_mask if os.path.exists(basal_mask) else ''\n",
    "        df.at[index, 'fu_img_path'] = fu_image if os.path.exists(fu_image) else ''\n",
    "        df.at[index, 'fu_mask_path'] = fu_mask if os.path.exists(fu_mask) else ''\n",
    "\n",
    "        if not os.path.exists(basal_image) or not os.path.exists(fu_image):\n",
    "            missing.append((hospital, pid, os.path.exists(basal_image), os.path.exists(fu_image)))\n",
    "\n",
    "# summary\n",
    "print(f\"Missing entries (hospital, id, has_basal, has_fu): {len(missing)}\")\n",
    "if missing:\n",
    "    print(missing[:50])\n",
    "\n",
    "# save augmented table\n",
    "df.to_csv('/media/cansu/DiskSpace/Cansu/HE_Prediction/all_data_with_paths.csv', index=False)\n",
    "print('Saved CSV with paths to all_data_with_paths.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f526b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved filtered CSV with both basal and fu images to data_with_both_basal_fu.csv\n"
     ]
    }
   ],
   "source": [
    "# filter the ones which have both basal and fu images\n",
    "df_filtered = df[(df['basal_img_path'] != '') & (df['fu_img_path'] != '') & (df['basal_mask_path'] != '') & (df['fu_mask_path'] != '')]\n",
    "df_filtered.to_csv('/media/cansu/DiskSpace/Cansu/HE_Prediction/data_with_both_basal_fu.csv', index=False)\n",
    "print('Saved filtered CSV with both basal and fu images to data_with_both_basal_fu.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5f7a831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataframe entries: 482\n",
      "Filtered dataframe entries: 456\n",
      "Number of entries removed: 26\n"
     ]
    }
   ],
   "source": [
    "# compare the filtered dataframe with the original one and print the number of entries removed\n",
    "print(f\"Original dataframe entries: {len(df)}\")\n",
    "print(f\"Filtered dataframe entries: {len(df_filtered)}\")\n",
    "print(f\"Number of entries removed: {len(df) - len(df_filtered)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb448eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entries per hospital in filtered dataframe:\n",
      "Hospital name\n",
      "Hospital Josep Trueta    209\n",
      "Hospital Vall Hebrón     167\n",
      "Hospital Clínic           47\n",
      "Hospital Sant Pau         33\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# number of entries from eachh hospital in the filtered dataframe\n",
    "print(\"Entries per hospital in filtered dataframe:\")\n",
    "print(df_filtered['Hospital name'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b917cb04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hospital: Hospital Clínic\n",
      "HE vicorob\n",
      "0.0    39\n",
      "1.0     8\n",
      "Name: count, dtype: int64\n",
      "Hospital: Hospital Sant Pau\n",
      "HE vicorob\n",
      "0.0    24\n",
      "1.0     9\n",
      "Name: count, dtype: int64\n",
      "Hospital: Hospital Vall Hebrón\n",
      "HE vicorob\n",
      "0.0    137\n",
      "1.0     30\n",
      "Name: count, dtype: int64\n",
      "Hospital: Hospital Josep Trueta\n",
      "HE vicorob\n",
      "0.0    166\n",
      "1.0     43\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# for each hospital count the number of \"he vicorob\" columns, if they are 1. and list numbers based on the hospital name\n",
    "for hospital in df_filtered['Hospital name'].unique():\n",
    "    hosp_df = df_filtered[df_filtered['Hospital name'] == hospital]\n",
    "    he_vicorob_counts = hosp_df['HE vicorob'].value_counts()\n",
    "    print(f\"Hospital: {hospital}\")\n",
    "    print(he_vicorob_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b9c56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Remove files with specific name in Hospital Vall Hebrón folder - space cleanup\n",
    "# path_hospital = \"/media/cansu/DiskSpace/Cansu/HE_Prediction/RAINS_vicorob/Hospital Vall Hebrón\"\n",
    "\n",
    "# for cases in os.listdir(path_hospital):\n",
    "#     basal_folder = os.path.join(path_hospital, cases, \"Basal\")\n",
    "#     fu_folder = os.path.join(path_hospital, cases, \"FU1\")\n",
    "\n",
    "#     # remove the files if it contains name hematoma_mask_fold0.nii.gz\n",
    "#     for folder in [basal_folder, fu_folder]:\n",
    "#         if os.path.exists(folder):\n",
    "#             for file in os.listdir(folder):\n",
    "#                 if \"hematoma_mask_fold4.nii.gz\" in file:\n",
    "#                     # print(f\"Removing file: {os.path.join(folder, file)}\")\n",
    "#                     os.remove(os.path.join(folder, file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098324d7",
   "metadata": {},
   "source": [
    "# Redesigning the Dataset and Dataloading process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ef5ee3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved IDs for Hospital Clínic to /media/cansu/DiskSpace/Cansu/HE_prediction_improved/data/Hospital_Clínic_ids.txt\n",
      "Saved IDs for Hospital Sant Pau to /media/cansu/DiskSpace/Cansu/HE_prediction_improved/data/Hospital_Sant_Pau_ids.txt\n",
      "Saved IDs for Hospital Vall Hebrón to /media/cansu/DiskSpace/Cansu/HE_prediction_improved/data/Hospital_Vall_Hebrón_ids.txt\n",
      "Saved IDs for Hospital Josep Trueta to /media/cansu/DiskSpace/Cansu/HE_prediction_improved/data/Hospital_Josep_Trueta_ids.txt\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"/media/cansu/DiskSpace/Cansu/HE_prediction_improved/data/data_with_both_basal_fu.csv\")\n",
    "##\n",
    "# bring all ids to string type and save them as txt file from all hospitals excepts Trueta\n",
    "df['id'] = df['id'].astype(str).str.zfill(3)\n",
    "hospitals = df['Hospital name'].unique().tolist()\n",
    "# hospitals.remove('Hospital Josep Trueta')\n",
    "\n",
    "for hospital in hospitals:\n",
    "    hosp_df = df[df['Hospital name'] == hospital]\n",
    "    ids = hosp_df['id'].tolist()\n",
    "    output_txt = f\"/media/cansu/DiskSpace/Cansu/HE_prediction_improved/data/{hospital.replace(' ', '_')}_ids.txt\"\n",
    "    with open(output_txt, 'w') as f:\n",
    "        for pid in ids:\n",
    "            f.write(f\"{pid}\\n\")\n",
    "    print(f\"Saved IDs for {hospital} to {output_txt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7508a53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 250 samples in test set from other hospitals.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x798e635c1ab0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "# from sklearn.utils.class_weight import compute_class_weight\n",
    "# import sys; sys.path.insert(0, os.path.abspath(\"../\"))\n",
    "# from dataset import *\n",
    "# from utils import *\n",
    "# from model import *\n",
    "import torch.utils.data as data\n",
    "import random\n",
    "import argparse\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import SimpleITK as sitk\n",
    "from torch.utils.data import Dataset\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "class ISLES24(Dataset):\n",
    "    \"\"\" ISLES24 Dataset\n",
    "\n",
    "    Now supports an optional `fold` argument. If `fold` is provided the\n",
    "    dataset will look for split files named `fold_{fold}_{split}_files.txt`\n",
    "    inside the `splits/` folder. If the fold-specific file does not exist\n",
    "    it falls back to the legacy `{split}_files.txt`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, base_dir=None, split='train', transform=None, fold: int = None):\n",
    "        self._base_dir = base_dir\n",
    "        self.transform = transform\n",
    "        self.sample_list = []\n",
    "\n",
    "        # build candidate path for split files\n",
    "        splits_dir = os.path.join(self._base_dir, 'splits')\n",
    "\n",
    "        if fold is not None:\n",
    "            candidate = os.path.join(splits_dir, f'fold_{fold}_{split}_files.txt')\n",
    "            if os.path.exists(candidate):\n",
    "                path = candidate\n",
    "                print(f\"Using fold {fold} split file: {os.path.basename(path)}\")\n",
    "            else:\n",
    "                raise FileNotFoundError(f\"Fold-specific file not found: {candidate}\")\n",
    "        else: \n",
    "            raise FileNotFoundError(\"Fold argument is required but not provided.\")\n",
    "\n",
    "        if not os.path.exists(path):\n",
    "            raise FileNotFoundError(f\"Split file not found: {path}\")\n",
    "\n",
    "        with open(path, 'r') as f:\n",
    "            self.image_list = f.readlines()\n",
    "\n",
    "        self.image_list = [item.replace('\\n', '').split(',')[0] for item in self.image_list]\n",
    "        print(\"Total {} samples in {} set.\".format(len(self.image_list), split))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        if isinstance(idx, str):\n",
    "            image_name = idx\n",
    "        else:\n",
    "            image_name = self.image_list[idx]\n",
    "\n",
    "        # open h5 file safely and read datasets\n",
    "        h5_path = os.path.join(self._base_dir, \"h5_files_preprocessed_no_znorm\", image_name)\n",
    "        with h5py.File(h5_path, 'r') as h5f:\n",
    "            # support files that use either 'data' or 'image' as the image dataset name\n",
    "            if 'data' in h5f:\n",
    "                image = h5f['data'][:]\n",
    "            elif 'image' in h5f:\n",
    "                image = h5f['image'][:]\n",
    "            else:\n",
    "                raise KeyError(f\"No 'data' or 'image' dataset found in {h5_path}\")\n",
    "\n",
    "            if 'label' in h5f:\n",
    "                label = h5f['label'][:]\n",
    "            elif 'gt' in h5f:\n",
    "                label = h5f['gt'][:]\n",
    "            else:\n",
    "                raise KeyError(f\"No 'label' or 'gt' dataset found in {h5_path}\")\n",
    "\n",
    "        # extract patient id from filename (robust to full paths)\n",
    "        base_name = os.path.basename(image_name)\n",
    "        patient_id = base_name.split('_')[0] if isinstance(base_name, str) else None\n",
    "\n",
    "        sample = {'image': image, 'label': label.astype(np.uint8), 'patient_id': patient_id}\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        # keep original idx for backward compatibility\n",
    "        sample[\"idx\"] = idx\n",
    "\n",
    "        return sample\n",
    "    \n",
    "\n",
    "\n",
    "class PredictionDataset(Dataset):\n",
    "    def __init__(self, base_dir=None, split='train', transform=None, fold: int = None, \n",
    "                 md_path: Path = None, test_other_hospitals: bool = False):\n",
    "        \n",
    "        self.md_df = pd.read_csv(md_path)\n",
    "        splits_dir = os.path.join(base_dir, 'splits')\n",
    "\n",
    "        if test_other_hospitals and split == 'test':\n",
    "            hospital_clinic_ids = pd.read_csv(\"/media/cansu/DiskSpace/Cansu/HE_prediction_improved/data/splits/Hospital_Clínic_ids.txt\", header=None)\n",
    "            # hospital_trueta_gt_ids = pd.read_csv(\"/media/cansu/DiskSpace/Cansu/HE_prediction_improved/data/splits/Hospital_Josep_Trueta_gt_ids.txt\", header=None)\n",
    "            hospital_trueta_vicorob_ids = pd.read_csv(\"/media/cansu/DiskSpace/Cansu/HE_prediction_improved/data/splits/Hospital_Josep_Trueta_pseudo_ids.txt\", header=None)\n",
    "            hospital_santpau_ids = pd.read_csv(\"/media/cansu/DiskSpace/Cansu/HE_prediction_improved/data/splits/Hospital_Sant_Pau_ids.txt\", header=None)\n",
    "            hospital_vallhebron_ids = pd.read_csv(\"/media/cansu/DiskSpace/Cansu/HE_prediction_improved/data/splits/Hospital_Vall_Hebrón_ids.txt\", header=None)\n",
    "            self.image_list = pd.concat([hospital_clinic_ids, hospital_trueta_vicorob_ids, hospital_santpau_ids, hospital_vallhebron_ids], ignore_index=True)\n",
    "            print(\"Total {} samples in test set from other hospitals.\".format(len(self.image_list)))\n",
    "            # all all ids with pseudo labels. \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        if isinstance(idx, str):\n",
    "            image_name = idx\n",
    "        else:\n",
    "            image_name = self.image_list[idx]\n",
    "\n",
    "        # for each id match the image and label paths from the dataframe\n",
    "        row = self.md_df[self.md_df['id'] == image_name]\n",
    "        if row.empty:\n",
    "            raise ValueError(f\"ID {image_name} not found in metadata dataframe.\")\n",
    "        \n",
    "        basal_img_path = row['basal_img_path'].values[0]\n",
    "        basal_mask_path = row['basal_mask_path'].values[0]\n",
    "\n",
    "        # read images using sitk\n",
    "        basal_img = sitk.GetArrayFromImage(sitk.ReadImage(basal_img_path))\n",
    "        basal_mask = sitk.GetArrayFromImage(sitk.ReadImage(basal_mask_path))\n",
    "\n",
    "        sample = {'image': basal_img, 'mask': basal_mask.astype(np.uint8), 'patient_id': image_name, 'pseudo_label': \n",
    "                  row['HE vicorob'].values[0], 'gt_label': row['HE real'].values[0]}\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        sample[\"idx\"] = idx\n",
    "        return sample\n",
    "\n",
    "repo_path = os.getcwd()\n",
    "CONFIG_PATH = repo_path + '/configs'\n",
    "with open(os.path.join(CONFIG_PATH, \"/media/cansu/DiskSpace/Cansu/HE_prediction_improved/configs/config_eff_t5_repeat_1_othermain.yml\")) as file:\n",
    "    config = yaml.safe_load(file)\n",
    "\n",
    "gpu = config[\"GPU\"]\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu\n",
    "threshold_name = config[\"threshold_name\"]\n",
    "experiment_sample= config[\"experiment_sample\"]\n",
    "threshold = config[\"threshold_percentage\"] # 0.5\n",
    "\n",
    "# # NUM_WORKERS=8\n",
    "# # MAX_EPOCHS=20\n",
    "# # MASK=True\n",
    "# # USE_2D=True\n",
    "# # FILTER_SEGMENTED = True\n",
    "# # PATIENCE = config[\"PATIENCE_EARLYSTOP\"]\n",
    "# # MODEL = config[\"MODEL\"]\n",
    "# # BACKBONE = config[\"BACKBONE\"]\n",
    "# # model = f\"{MODEL}\"\n",
    "# # gradient_accumulation_steps =  1\n",
    "# # pw_based = \"mean\" # the way the pw is calculated.\n",
    "# # test_pw_based = \"mean\"\n",
    "# # no_ivh = config[\"NO_IVH\"] # Eliminate ivh cases from the dataset\n",
    "# # task = config[\"TASK\"]\n",
    "# # lesion = config[\"LESION\"]\n",
    "# # test_type = config[\"TEST_TYPE\"]\n",
    "\n",
    "md_path = repo_path + \"/data/data_with_both_basal_fu.csv\"\n",
    "df = pd.read_csv(md_path)\n",
    "df\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "dataset = PredictionDataset(base_dir=repo_path, split='test', transform=None, fold=1, \n",
    "                            md_path=md_path, test_other_hospitals=True)\n",
    "dataloader = DataLoader(dataset, batch_size=2, num_workers=4, shuffle=False)\n",
    "dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef96e3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseudo_labels = df['HE vicorob'].values  \n",
    "gt_labels = df['HE real'].values\n",
    "patient_id= df['id'].values\n",
    "hospital_bname = df['Hospital name'].values\n",
    "basal_img_path = df['basal_img_path'].values\n",
    "basal_mask_path = df['basal_mask_path'].values\n",
    "fu_img_path = df['fu_img_path'].values\n",
    "fu_mask_path = df['fu_mask_path'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04a7a15f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
       "       0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0.,\n",
       "       1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.,\n",
       "       0., 0., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
       "       0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1., 0.,\n",
       "       0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "       1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseudo_labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3dunet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
